# MedGuard AI

A comprehensive medical AI analysis system that provides real-time hallucination detection, citation verification, and HIPAA compliance checking for medical AI outputs. This system acts as middleware between your chatbot and end users, ensuring every AI response meets clinical standards before delivery.

## ğŸ¯ Overview

MedGuard AI is a full-stack application that monitors, analyzes, and verifies medical AI chatbot responses. It consists of:

- **Backend**: FastAPI-based agentic system using Google Gemini AI for analysis
- **Frontend**: Modern React dashboard with real-time monitoring and compliance reporting
- **Agents**: Specialized AI agents for hallucination detection, citation checking, and compliance validation

### Key Features

- ğŸ” **Hallucination Detection**: Automatically detects potential hallucinations in LLM outputs using real-time web verification
- ğŸ“š **Citation Verification**: Validates citations against PubMed, DOI, and web sources
- ğŸ›¡ï¸ **HIPAA Compliance**: Ensures medical content meets HIPAA and FDA compliance standards
- ğŸ“Š **Real-time Monitoring**: Live dashboard showing verification status and detailed compliance reports
- ğŸ”„ **Background Processing**: Non-blocking analysis that doesn't disrupt chatbot flow
- ğŸ“ **Audit Trail**: Complete history of all prompts, responses, and verification results

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Chatbot       â”‚
â”‚   (External)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ POST /api/bot-output
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI Backendâ”‚
â”‚  - Agents       â”‚
â”‚  - Analysis     â”‚
â”‚  - Reports      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ REST API
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  React Frontend â”‚
â”‚  - Dashboard    â”‚
â”‚  - Reports      â”‚
â”‚  - History      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Setup

### Prerequisites

- **Python 3.8+** (for backend)
- **Node.js 18+** (for frontend)
- **Google Gemini API Key** ([Get one here](https://aistudio.google.com/))
- **Google Search API Key** ([Get one here](https://console.cloud.google.com/))

### Environment Variables

**Backend (.env)**:
```env
GOOGLE_API_KEY=your_gemini_api_key
GOOGLE_SEARCH_API_KEY=your_search_api_key
GOOGLE_GEMINI_MODEL=gemini-pro
FLASK_ENV=production
FLASK_DEBUG=False
```

**Frontend (.env)**:
```env
VITE_CHATBOT_BASE_URL=https://your-chatbot-url.com
VITE_API_BASE_URL=https://your-backend-url.com
```

### Installation

```bash
# Backend
cd backend
pip install -r requirements.txt

# Frontend
cd frontend
npm install
npm run build
```

## ğŸ“– Usage

### API Endpoints

#### Main Analysis Endpoint
```bash
POST /api/report
Content-Type: application/json

{
  "original_prompt": "What are the side effects of aspirin?",
  "llm_output": "Aspirin can cause stomach bleeding..."
}
```

#### Bot Output Ingestion
```bash
POST /api/bot-output
Content-Type: application/json

{
  "prompt": "User's question",
  "response": "AI's response",
  "metadata": { "conversationId": "optional-id" }
}
```

#### Other Endpoints
- `GET /api/bot-output` - List all captured bot outputs
- `GET /api/report/{response_id}` - Get analysis report for a specific response
- `GET /api/agents` - List available agents
- `GET /docs` - Interactive API documentation (Swagger UI)



## ğŸ¤– Agent System

### HallucinationGuard Agent
Detects potential hallucinations in LLM outputs through:
- Citation extraction and verification
- Real-time web search verification
- Source consistency checking
- Risk level assessment (LOW, MEDIUM, HIGH, CRITICAL)

### Citation Checker Agent
Verifies citations against:
- PubMed API (PMID validation)
- DOI resolution
- General web search
- Citation-claim support analysis

### Compliance Checker Agent
Ensures HIPAA and medical compliance by checking:
- PHI (Protected Health Information) detection
- Required medical disclaimers
- Emergency situation handling
- Medical advice appropriateness
- FDA compliance

## ğŸ“Š Response Structure

```json
{
  "report_id": "report_1234",
  "analysis": {
    "hallucination_analysis": {
      "citations_found": 1,
      "risk_level": "MEDIUM"
    },
    "compliance_analysis": {
      "compliance_score": 85,
      "overall_status": "MOSTLY_COMPLIANT"
    },
    "combined_assessment": {
      "overall_risk_level": "MEDIUM",
      "recommendation": "Review and address identified issues before use"
    }
  },
  "status": "completed",
  "timestamp": "2024-01-01T12:00:00Z"
}
```

### Risk Levels
- **LOW**: Content appears safe for use
- **MEDIUM**: Minor issues detected, review recommended
- **HIGH**: Significant issues, major revision needed
- **CRITICAL**: Serious violations, content unsafe for use

## ğŸ—‚ï¸ Project Structure

```
aiatl2025/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                 # Main FastAPI application
â”‚   â”œâ”€â”€ config.py               # Configuration settings
â”‚   â”œâ”€â”€ requirements.txt      # Python dependencies
â”‚   â””â”€â”€ agents/
â”‚       â”œâ”€â”€ base_agent.py
â”‚       â”œâ”€â”€ gemini_agent.py
â”‚       â”œâ”€â”€ hallucination_guard.py
â”‚       â”œâ”€â”€ citation_checker.py
â”‚       â””â”€â”€ compliance_checker.py
â”‚
â””â”€â”€ frontend/
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ App.tsx
    â”‚   â”œâ”€â”€ pages/Index.tsx
    â”‚   â”œâ”€â”€ components/
    â”‚   â”œâ”€â”€ services/
    â”‚   â””â”€â”€ hooks/
    â””â”€â”€ package.json
```

## ğŸ“ API Usage Limits

- **Gemini API**: Free tier includes 15 requests per minute
- **Search API**: 100 free queries per day, then $5 per 1000 queries


---

**Built with â¤ï¸ for medical AI safety and compliance**
